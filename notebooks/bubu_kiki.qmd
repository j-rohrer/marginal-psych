---
title: "Example: Bubu/kiki"
author: "Julia Rohrer"
date: "`r Sys.Date()`"
format: 
  html:
    embed-resources: true
    toc: true

---

# Overview

Substantively, we are looking at the bouba/kiki effect: This is the observation that people tend to associate particular sounds with particular shapes (e.g., rounded shapes with bouba, angular shapes with kiki), i.e., sound-shape mapping. [Heyman et al. (2019)](https://journals.sagepub.com/doi/10.1177/0956797619875482) conducted a replication study of [Hung et al. (2017)](https://journals.sagepub.com/doi/full/10.1177/0956797616677313) to test whether congruent stimuli (bubi spelled out in a round shape, kiki spelled out in an angular shape) become visible faster. If this were the case, it would indicate that sound-shape mapping occurs prior to conscious awareness.

Before we start, let's execute a helper script that loads the necessary dependencies.

```{r}
source(here::here("scripts/load.R"))

```

# Data reading and cleaning

Here we prepare the data for our example 1. 
A lot of this code is just copied from the file that the authors provided on the OSF, downloadable from [https://osf.io/t5phc/](https://osf.io/t5phc/).
The authors provided a single RMarkdown document; we only copied the relevant parts, which works better for our present purposes.

```{r readData}
dat <- read.csv(here("data/bubu_kiki.csv")) |>
    transform(
        Shape = ifelse(Spikes == 1, "spiky", "rounded"),
        Word = ifelse(Kiki == 1, "kiki", "bubu"),
        Congruent = factor(
            ifelse(Congruent == 1, "Congruent", "Incongruent"), 
            c("Incongruent", "Congruent"))
    ) |>
  rename(
    reaction_time = rt,
    congruence = Congruent,
    shape = Shape,
    word = Word,
    participant = pp
  )
```

In our analyses, there are 3 main variables of interest:

1. `shape`: The shape of the displayed word.
2. `word`: The word displayed.
3. `congruent`: A binary variable equal to 1 when the word and shape are congruent, and 0 otherwise.
4. `reaction_time`: The reaction time of the participant in second.

Below, we show four arbitrarily-chosen observations from the dataset to illustrate the relationship between `shape`, `word`, and `congruence`.

```{r}
bybind <- function(x, ...) do.call(rbind, by(x, ...))
tab <- bybind(dat, ~ shape + word, FUN = \(x) x[1, c("shape", "word", "congruence", "reaction_time")])
tt(tab, caption = "Four observations from the Bubu/Kiki dataset.")
```
# Generalized mixed effects model (mod1)
This closely mirrors the analyses conducted by both Hung et al. (2017) and Heyman et al. (2019).

## Setting up the model

```{r}

# Fit the model
mod1 <- glmer(
    reaction_time ~ congruence +
        (1 + congruence | participant),
    data = dat,
    family = Gamma(link = "log")
)

# Take a look at the coefficients
parameters(mod1)
```

## Interpreting mod1 with marginaleffects

### Average predictions and counterfactual comparisons
```{r}
# Average predictions
avg_predictions(mod1, by = "congruence")

# Counterfactual comparisons
avg_comparisons(mod1, variables = "congruence")
```

### Conducting an equivalence test
```{r}
avg_comparisons(mod1, variables = "congruence",
               equivalence = c(-0.18, -0.06))

```

### Effect Heterogeneity
```{r}
# Individual-level comparisons
comparisons(mod1, variables = "congruence")

mod1_comparisons <- comparisons(mod1, variables = "congruence")

color_prediction <- "#0072B2"
color_comparison <- "#56B4E9"
color_slope <- "#009E73"
color_neutral <- "#BBBBBB"

ggplot(dat = mod1_comparisons, aes(x = estimate)) +
  geom_density(bw = 0.015, fill = color_comparison, alpha = .2) +
  theme_classic() +
  geom_vline(xintercept = 0, color = color_neutral) +
  xlab("Congruence effect (in seconds)") +
  ylab("Density") +
  coord_cartesian(xlim = c(-0.2, 0.2))
ggsave(here("plots/fig3b.png"), width = 3, height = 3)
```



# Modeling both experimental factors separately (mod2)

## Setting up the model
```{r}
mod2 <- glmer(
    reaction_time ~ word + shape + word:shape +
        (1 + word + shape + word:shape | participant),
    data = dat,
    family = Gamma(link = "log")
)

# Take a look at the coefficients
parameters(mod2)
```

## Model interpretation with marginaleffects 

### Average expected reaction times for each combination of `word` and `shape`

```{r}
avg_predictions(mod2, by = c("word", "shape"))

mod2_predictions <- avg_predictions(mod2, by = c("word", "shape"))

ggplot(mod2_predictions, 
       aes(x = as.factor(word), 
           y = estimate, 
           group = shape, 
           shape = as.factor(shape), 
           color = as.factor(shape))) +
  geom_point(position = position_dodge(width = 0.3)) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high),
                position = position_dodge(width = 0.3),
                width = .3) +
  #scale_x_discrete(labels = c("0" = "bubu", "1" = "kiki")) +
  scale_color_discrete(labels = c("0" = "rounded", "1" = "spiky")) +
  scale_shape_discrete(labels = c("0" = "rounded", "1" = "spiky")) +
  labs(x = "Displayed word",
       y = "Reaction time in seconds (95% CI)",
       color = "shape",
       shape = "shape") +
  coord_cartesian(ylim = c(2.5, 4.5))

ggsave(here("plots/fig3c.png"), width = 3, height = 3)
```

### Testing the interaction
```{r}
avg_comparisons(mod2, variables = "shape", by = "word", hypothesis = "b2- b1 = 0")

```

### Recovering the congruent vs. incongruent contrast from mod2

```{r}
avg_predictions(mod2, by = "congruence", hypothesis = "b2 - b1 = 0")
```

Reaction time appears shorter (faster) for congruent stimuli.^[Note that the `by` argument accepts any variable from the dataset, even if that variable is not a predictor in the model.]



# Additionally taking into account the uncertainty in the random effects
So far, we only took into account the uncertainty in the fixed-effect parameters.
This could understate the total uncertainty in our predictions and comparisons, as they do include the random effects.

## Frequentist solution
```{r, eval = FALSE}
# At the point of writing, this requires the dev version of marginaleffects

remotes::install_github("vincentarelbundock/marginaleffects")

library(tictoc)
plan(multisession, workers = 8) 
options(marginaleffects_inferences_parallel = TRUE) 

options(marginaleffects_parallel_packages = c("lme4")) 

tic()
inferences <- avg_comparisons(mod2, 
                              variables = "shape", 
                              by = "word", 
                              hypothesis = "b2- b1 = 0") |>
  inferences(method = "boot", R = 5, parallel = "multicore")
toc()
# This takes very long, 108 seconds for R = 5 on my machine

```

## Bayesian solution


```{r, eval=FALSE} 

tic()
mod2_bayesian <- brm( 
   reaction_time ~ word + shape + word:shape + 
     (1 + word + shape + word:shape | participant), 
   data = dat, 
   family = Gamma(link = "log"), 
   cores = 4) 
avg_predictions(mod2_bayesian, by = c("word", "shape")) 
toc()
```